{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b498c2b0-97e9-4281-8564-fc04942954e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, concatenate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77dc2ee1-64ae-4ad6-a35d-19a0ef97de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_images_from_dir(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            # Resizing \n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            images.append(img)\n",
    "            labels.append(directory.split('/')[-1])  \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09798bbb-96e3-4940-b8ae-7a6ccc1b0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable assignment\n",
    "ad_creatives_dir = \"ad-creatives\"\n",
    "non_ad_creatives_dir = \"non_ad-creatives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968d5c3-3930-4d97-b284-11c8a84ed240",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_images, ad_labels = load_images_from_dir(ad_creatives_dir)\n",
    "non_ad_images, non_ad_labels = load_images_from_dir(non_ad_creatives_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8ea009-1ab2-4514-a193-a9c589225c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.concatenate((ad_images, non_ad_images), axis=0)\n",
    "all_labels = np.concatenate((ad_labels, non_ad_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facbb677-ef44-460c-a2df-3e703c212f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(all_images.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "all_images = all_images[indices]\n",
    "all_labels = all_labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cc3333-b452-42f8-a23a-6347ef77517c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all images: (0,)\n",
      "Shape of all labels: (0,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of all images:\", all_images.shape)\n",
    "print(\"Shape of all labels:\", all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6a5f52-a31e-4db6-b20d-49ec3418ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,      \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.2,        \n",
    "    zoom_range=0.2,         \n",
    "    horizontal_flip=True,   \n",
    "    fill_mode='nearest'     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a01f6f-653a-499d-82b2-537741d1b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(images):\n",
    "    augmented_images = []\n",
    "    for image in images:\n",
    "        image = np.expand_dims(image, axis=0)  \n",
    "        augmented_image = next(datagen.flow(image))[0]\n",
    "        augmented_images.append(augmented_image)\n",
    "    return np.array(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ece3ea2-d214-4c31-8047-298994e51c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_ad_images = augment_images(ad_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde1444a-f7d0-49ec-89ca-8520d1f09ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_non_ad_images = augment_images(non_ad_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faede91d-a7d4-4c72-a533-9b3d6c31cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc6586a-fb15-4bbf-9e67-bbe5ec1a9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical to numerical\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels_encoded = label_encoder.fit_transform(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ecdba09-87e6-4670-b15d-7f035f9f1f10",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_labels_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\saksh\\OneDrive\\Desktop\\github\\Ad-creatives\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\saksh\\OneDrive\\Desktop\\github\\Ad-creatives\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\saksh\\OneDrive\\Desktop\\github\\Ad-creatives\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2419\u001b[0m     )\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919bef0b-c025-4b6c-b46c-8b09f179a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ea22c-ad01-43fd-8650-7c37812347d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f97f82-a8e2-410d-aa14-ba7c2014ddef",
   "metadata": {},
   "source": [
    "ResNet would be a good choice here for model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898f938-2986-40c3-b2ca-c72fc7ccd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1005b-fe46-4ab1-86ea-40fcb7edbc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd67f7-2dff-4a48-a632-9b8e9d13ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e86df5-ddc6-4f48-9bf4-86a3be31ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)  \n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21be715-8b20-4014-bb76-cf1a63a8925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0100dc-6f60-4912-9557-38add94797fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a8c03-18dd-4c26-8c2e-ea3a070c2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.9\n",
    "\n",
    "learning_rate_schedule = ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps, decay_rate, staircase=True\n",
    ")\n",
    "optimizer = Adam(learning_rate=learning_rate_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ae703-fb55-4f5d-bdd3-616df9331e76",
   "metadata": {},
   "source": [
    "Now training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104f209-84f6-4475-bfb5-1220551a56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,  \n",
    "    batch_size=32,  \n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a3235-082e-4d3e-9b58-6841029b8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82b6fa-6209-4174-b46b-68751590db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363d675-86a6-4a3f-9a9f-1a22cef54844",
   "metadata": {},
   "source": [
    "\n",
    "Manually checking using few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee4ae0-cfbb-49b4-975b-d0a49e71ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ae11c-beda-4a76-85d4-abc5d0b3f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(X_test.shape[0], size=5, replace=False)\n",
    "sample_images = X_test[sample_indices]\n",
    "sample_labels = y_test[sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c2eee-8219-4599-868b-62df9c9a4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(sample_images)\n",
    "predicted_labels = np.round(predictions).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251aaf42-1b8f-4f30-8108-c2367d88a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(sample_indices)):\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"Predicted: {predicted_labels[i]}, True: {sample_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047656d5-82f2-44d6-913f-3b0b07400489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_labels_to_strings(labels):\n",
    "    label_map = {0: \"ad\", 1: \"non-ad\"}\n",
    "    return [label_map[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03211a-b5c0-481d-99b2-61fb7682c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(images, labels, predictions):\n",
    "    for i in range(len(images)):\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Predicted: {predictions[i]}, True: {labels[i]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "num_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5f8e8-d190-4cd2-9164-70b994a945e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    sample_indices = np.random.choice(X_test.shape[0], size=num_samples, replace=False)\n",
    "    sample_images = X_test[sample_indices]\n",
    "    sample_labels = y_test[sample_indices]\n",
    "\n",
    "    predictions = model.predict(sample_images)\n",
    "    predicted_labels = np.round(predictions).astype(int)\n",
    "\n",
    "    display_sample_images(sample_images, sample_labels, predicted_labels)\n",
    "\n",
    "    user_input = input(\"Do you want to continue checking? (yes/no): \").lower()\n",
    "    if user_input != 'yes':\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f48680-c16b-4fad-9233-2422282e4bb1",
   "metadata": {},
   "source": [
    "Add probability scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef54dd-ac73-4088-b5e5-6ff8de5c2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"till now good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433067f-73e1-4588-aaa8-58b7cf3b15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Define a function to display sample images with predictions and probability scores\n",
    "def display_sample_images_with_prob(images, labels, predictions, prob_scores):\n",
    "    for i in range(len(images)):\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Predicted: {predictions[i]}, Probability: {prob_scores[i][0]:.2f}, True: {labels[i]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.round(y_pred_prob).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Display sample images with predictions and probability scores\n",
    "display_sample_images_with_prob(X_test, y_test, y_pred, y_pred_prob)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
